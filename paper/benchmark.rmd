---
output: github_document
---

## Benchmark

This is a version of WEAT written entirely in R.

```{r}
require(purrr)
require(lsa)

take <- function(word, w) {
    return(as.vector(w[word, , drop = FALSE]))
}

get_x <- function(w, words) {
    purrr::map(words, take, w = w)
}

g <- function(c, A, B, w) {
    A_emb <- get_x(w, A)
    B_emb <- get_x(w, B)
    c_emb <- get_x(w, c)[[1]]
    a_cos_diff <- mean(purrr::map_dbl(A_emb, ~cosine(., c_emb)))
    b_cos_diff <- mean(purrr::map_dbl(B_emb, ~cosine(., c_emb)))
    return(a_cos_diff - b_cos_diff)
}

.clean <- function(x, w_lab, verbose = FALSE) {
    new_x <- intersect(x, w_lab)
    if (length(new_x) < length(x) & verbose) {
        print("Some word(s) are not available in w.")
    }
    return(new_x)
}


r_weat <- function(w, S, T, A, B, verbose = FALSE) {
    w_lab <- rownames(w)
    A <- .clean(A, w_lab, verbose = verbose)
    B <- .clean(B, w_lab, verbose = verbose)
    S <- .clean(S, w_lab, verbose = verbose)
    T <- .clean(T, w_lab, verbose = verbose)
    S_diff <- purrr::map_dbl(S, g, A, B, w)
    T_diff <- purrr::map_dbl(T, g, A, B, w)
    ## union_diff <- purrr::map_dbl(union(S, T), g, A, B, w)
    return((mean(S_diff) - mean(T_diff)) / sd(c(S_diff, T_diff)))
}
require(compiler)

r_weat_c <- cmpfun(r_weat)
```

## The Calikskan et al. example.

```{r}
require(sweater)
S2 <- c("math", "algebra", "geometry", "calculus", "equations",
        "computation", "numbers", "addition")
T2 <- c("poetry", "art", "dance", "literature", "novel", "symphony",
        "drama", "sculpture")
A2 <- c("male", "man", "boy", "brother", "he", "him", "his", "son")
B2 <- c("female", "woman", "girl", "sister", "she", "her", "hers",
        "daughter")
r_weat(glove_math, S2, T2, A2, B2)
r_weat_c(glove_math, S2, T2, A2, B2)

```

The same implementation in C++ from `sweater`

```{r}
calculate_es(query(glove_math, S2, T2, A2, B2))
cpp_weat <- function(w, S, T, A, B) {
    calculate_es(query(w, S, T, A, B))
}
```

The C++ implementation in `sweater` is >10x faster. Byte-code compilation (`r_weat_c`) can bring about almost no little improvement.

```{r}
require(bench)
benchmark_res <- bench::mark(
                            r_weat(glove_math, S2, T2, A2, B2),
                            r_weat_c(glove_math, S2, T2, A2, B2),
                            cpp_weat(glove_math, S2, T2, A2, B2),
                            relative = TRUE)
benchmark_res
```

### Random benchmark

In this benchmark, we test how the lengths of S/T/A/B affect the performance. `sweater` is at least 7x faster.

```{r}
set.seed(12121)
stab_length <- seq(10, 100, 10)
r_bench <- function(stab_n) {
    w_lab <- rownames(googlenews)
    S <- sample(w_lab, stab_n)
    T <- sample(w_lab, stab_n)
    A <- sample(w_lab, stab_n)
    B <- sample(w_lab, stab_n)
    bench::mark(r_weat(googlenews, S, T, A, B),
                r_weat_c(googlenews, S, T, A, B),
                cpp_weat(googlenews, S, T, A, B),
                relative = TRUE)
}

res <- map(stab_length, r_bench)
res %>% map_dfr(~.[1,3]) %>% dplyr::mutate(stab_length = stab_length)
```

### versus WEFE

The hidden gem of this package is the function `read_word2vec`. It is so flexible and yet speedy. In the following example, we are going to compare the typical task of the bias detection pipeline:

1. read a pretrained word embedding file (In this case GloVE, 5.3 GB)
2. do WEAT

`read_word2vec` is based on the C++ based function `data.table::fread` and it can read almost all formats (word2vec, glove, fastText, etc). The entire workflow can be finished in less than a minute.

```{bash}
time Rscript bench.R
```

The Python workflow, however, needs to use `gensim` to read the pretained word embedding file and it can't read GLoVE format directly and the file needs to first convert to word2vec [^1]. The `KeyedVectors.load_word2vec_format` is not written in a low-level language and thus is many times slower than `read_word2vec`. And the result reported is not the same as the numbers reported in Caliskan et al.

```{bash}
time python3 bench.py
```

## Testing environment

```{r}
sessionInfo()
```

```{bash}
neofetch --stdout
```

---

[^1]: Actually the only difference between the two format is the GLoVE format doesn't record the dimensionality of the matrix in the first line.
